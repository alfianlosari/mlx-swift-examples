#  Llama

This is a port of the llama model from:

- https://github.com/ml-explore/mlx-examples/blob/main/llms/mlx_lm/models/llama.py

You can use this to load models from huggingface, e.g.:

- https://huggingface.co/mlx-community/Mistral-7B-v0.1-hf-4bit-mlx

For example:

```
# Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install

# get the model weights
cd ~
git clone https://huggingface.co/mlx-community/Mistral-7B-v0.1-hf-4bit-mlx
```

See [llm-tool](../../Tools/llm-tool)
